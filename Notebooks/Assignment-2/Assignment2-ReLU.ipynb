{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "import sklearn as skl\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization \n",
    "This is where we initialize the dataset and the hidden network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load Dataset\n",
    "inputFilenameWithPath = 'train_data.txt'\n",
    "inputData = np.loadtxt(inputFilenameWithPath, delimiter=\",\")\n",
    "n_inputs = len(inputData[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in inputData]))\n",
    "# Initialize a single layer neural network with n_neurons in the hidden layer\n",
    "def initialize_network(n_inputs, n_neurons , n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer1 = [{'weights' :[random() for layer in range(n_inputs)]} for i in range(n_neurons)]\n",
    "\tnetwork.append(hidden_layer1)\n",
    "\thidden_layer2 = [{'weights' :[random() for layer in range(n_neurons)]} for i in range(n_neurons)]\n",
    "\tnetwork.append(hidden_layer2)\n",
    "\toutput_layer = [{'weights' :[random() for layer in range(n_neurons)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the input and weights initialization\n",
    "Print the layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The product summation and sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def weights_input_product(weights, inputs):\n",
    "\tsummation = 0\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tsummation += weights[i] * inputs[i]\n",
    "\treturn summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    if(z > 0):\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def relu1(z):\n",
    "\treturn 1.0 / (1.0 + exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Send the list of outputs for each layer\n",
    "def forward_propagate(network, inputData):\n",
    "    outputs = []\n",
    "    inputRecord = inputData\n",
    "    relu_op = np.vectorize(lambda data: relu(data))\n",
    "    for layer in network: # Iterate over the layers\n",
    "        layer_output = []\n",
    "        i = 0\n",
    "        for neuron in layer: # Iterate for all neurons\n",
    "            summation = weights_input_product(neuron['weights'],inputRecord)\n",
    "            if i < len(network):\n",
    "                activation = relu_op(summation)\n",
    "            else:\n",
    "                activation = softmax(summation)\n",
    "            neuron['output'] = activation\n",
    "            layer_output.append(activation)\n",
    "        outputs.append(layer_output)\n",
    "        inputRecord = layer_output\n",
    "    return layer_output\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    sum = np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    return np.divide(np.exp(z),sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(z):\n",
    "    if(z > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def transfer_derivative1(z):\n",
    "    return z*(1-z)\n",
    "\n",
    "def transfer_softmax_derivative(signal):\n",
    "    return signal*(1-signal) + (1 - signal)*signal\n",
    "\n",
    "\n",
    "def transfer_softmax_derivative1(signal):\n",
    "    return np.multiply( signal, 1 - signal ) + sum(\n",
    "            # handle the off-diagonal values\n",
    "            - signal * np.roll( signal, i, axis = 1 )\n",
    "            for i in xrange(1, signal.shape[1] )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tif j != len(network)-1:\n",
    "\t\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])#Sigmoid derivative for all other layers\n",
    "\t\t\telse:\n",
    "\t\t\t\tneuron['delta'] = errors[j] * transfer_softmax_derivative(neuron['output'])#softmax derivative for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train via SGD\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs,n_iterations):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tn_examples = len(train)        \n",
    "\t\trandom_samples = train[np.random.choice(train.shape[0], n_iterations, replace=False), :];\n",
    "\t\tfor row in random_samples:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\t#print(\"Expected shape\",expected)\n",
    "\t\t\texpected[int(row[-1])] = 1\n",
    "\t\t\t#expected[1] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('Epoch=%d, Loss=%.3f' % (epoch, sum_error))\n",
    "    \n",
    "\tprint(\"\\n\\nFinal Weights\")\n",
    "\tfor layer in network:\n",
    "\t\tlayerWeights = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tlayerWeights.append(neuron['weights'])\n",
    "\t\tprint layerWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    sum = np.sum(np.exp(z))\n",
    "    return np.divide(np.exp(z),sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "p =[ 0.0871086  , 0.91817548]\n",
    "\n",
    "def predict(network, row):\n",
    "\tp=outputs = forward_propagate(network, row)\n",
    "\t#print(outputs[0],outputs[1])\n",
    "\t#print(np.asarray(outputs).T)\n",
    "\treturn outputs.index(max(outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Loss=152.820\n",
      "Epoch=1, Loss=100.000\n",
      "Epoch=2, Loss=100.000\n",
      "Epoch=3, Loss=100.000\n",
      "Epoch=4, Loss=100.000\n",
      "Epoch=5, Loss=100.000\n",
      "Epoch=6, Loss=100.000\n",
      "Epoch=7, Loss=100.000\n",
      "Epoch=8, Loss=100.000\n",
      "Epoch=9, Loss=100.000\n",
      "Epoch=10, Loss=100.000\n",
      "Epoch=11, Loss=100.000\n",
      "Epoch=12, Loss=100.000\n",
      "Epoch=13, Loss=100.000\n",
      "Epoch=14, Loss=100.000\n",
      "Epoch=15, Loss=100.000\n",
      "Epoch=16, Loss=100.000\n",
      "Epoch=17, Loss=100.000\n",
      "Epoch=18, Loss=100.000\n",
      "Epoch=19, Loss=100.000\n",
      "Epoch=20, Loss=100.000\n",
      "Epoch=21, Loss=100.000\n",
      "Epoch=22, Loss=100.000\n",
      "Epoch=23, Loss=100.000\n",
      "Epoch=24, Loss=100.000\n",
      "Epoch=25, Loss=100.000\n",
      "Epoch=26, Loss=100.000\n",
      "Epoch=27, Loss=100.000\n",
      "Epoch=28, Loss=100.000\n",
      "Epoch=29, Loss=100.000\n",
      "Epoch=30, Loss=100.000\n",
      "Epoch=31, Loss=100.000\n",
      "Epoch=32, Loss=100.000\n",
      "Epoch=33, Loss=100.000\n",
      "Epoch=34, Loss=100.000\n",
      "Epoch=35, Loss=100.000\n",
      "Epoch=36, Loss=100.000\n",
      "Epoch=37, Loss=100.000\n",
      "Epoch=38, Loss=100.000\n",
      "Epoch=39, Loss=100.000\n",
      "Epoch=40, Loss=100.000\n",
      "Epoch=41, Loss=100.000\n",
      "Epoch=42, Loss=100.000\n",
      "Epoch=43, Loss=100.000\n",
      "Epoch=44, Loss=100.000\n",
      "Epoch=45, Loss=100.000\n",
      "Epoch=46, Loss=100.000\n",
      "Epoch=47, Loss=100.000\n",
      "Epoch=48, Loss=100.000\n",
      "Epoch=49, Loss=100.000\n",
      "\n",
      "\n",
      "Final Weights\n",
      "[[190.1948223736845, -27.783855815763435], [-9.5369215616528091, 1.7465082143407404], [-4610.0204979067221, 679.57317190567301]]\n",
      "[[-19.028689571529323, -23.127913917524232, -27.609644797934774], [-11.385540118008137, -12.553875887614625, -15.222977434489801], [279.43354477734977, 337.41093181814568, 392.65644624408145]]\n",
      "[[-27.180125537995416, -22.124059030173278, -16.012203759147059], [-2.5039476383518235, -2.9589233752719792, -1.9585555721561894]]\n",
      "\n",
      "Training Precision=0.50\n",
      "Training Recall=0.50\n",
      "Training F1 Score=0.50\n",
      "\n",
      "---------------------------- Testing the predictions -------------------------\n",
      "\n",
      "Test Precision=0.50\n",
      "Test Recall=0.50\n",
      "Test F1 Score=0.50\n"
     ]
    }
   ],
   "source": [
    "# Run the code now\n",
    "\n",
    "#Do the training first.\n",
    "seed(1)\n",
    "inputFilenameWithPath = 'train_data.txt'\n",
    "prediction_op = np.vectorize(lambda data: predict(network, data))\n",
    "inputData = np.loadtxt(inputFilenameWithPath, delimiter=\",\")\n",
    "n_inputs = len(inputData[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in inputData]))\n",
    "n_neurons = 3\n",
    "network = initialize_network(n_inputs, n_neurons, n_outputs)\n",
    "sgd_learning_rate = 0.6\n",
    "numberOfEpochs  = 50\n",
    "numberOfExamplesPerEpoch = 100\n",
    "train_network(network, inputData, sgd_learning_rate, numberOfEpochs, n_outputs,numberOfExamplesPerEpoch)\n",
    "predictions = []\n",
    "truth = inputData[:,2]\n",
    "for row in inputData:\n",
    "\tprediction = predict(network, row)\n",
    "\tpredictions.append(prediction)\n",
    "f1 = skl.metrics.f1_score(truth, predictions, average='micro')  \n",
    "precision = skl.metrics.precision_score(truth, predictions, average='micro')\n",
    "recall = skl.metrics.recall_score(truth, predictions, average='micro')\n",
    "print('\\nTraining Precision=%.2f' % (precision))\n",
    "print('Training Recall=%.2f' % (recall))\n",
    "print('Training F1 Score=%.2f' % (f1))\n",
    "    \n",
    "print('\\n---------------------------- Testing the predictions -------------------------')    \n",
    "# Test making predictions with the network\n",
    "inputFilenameWithPath = 'test_data.txt'\n",
    "dataset = np.loadtxt(inputFilenameWithPath, delimiter=\",\")\n",
    "\n",
    "#predictions = prediction_op(dataset[:,:2])\n",
    "truth = dataset[:,2]\n",
    "predictions = []\n",
    "for row in dataset:\n",
    "\tprediction = predict(network, row)\n",
    "\tpredictions.append(prediction)\n",
    "\t#print('Expected=%d, Got=%d' % (row[-1], prediction))\n",
    "f1 = skl.metrics.f1_score(truth, predictions, average='micro')  \n",
    "precision = skl.metrics.precision_score(truth, predictions, average='micro')\n",
    "recall = skl.metrics.recall_score(truth, predictions, average='micro')\n",
    "print('\\nTest Precision=%.2f' % (precision))\n",
    "print('Test Recall=%.2f' % (recall))\n",
    "print('Test F1 Score=%.2f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
