{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "import sklearn as skl\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization \n",
    "This is where we initialize the dataset and the hidden network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "inputFilenameWithPath = 'train_data.txt'\n",
    "inputData = np.loadtxt(inputFilenameWithPath, delimiter=\",\")\n",
    "n_inputs = len(inputData[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in inputData]))\n",
    "# Initialize a single layer neural network with n_neurons in the hidden layer\n",
    "def initialize_network(n_inputs, n_neurons , n_outputs):\n",
    "\tnetwork = list()\n",
    "\thidden_layer1 = [{'weights' :[random() for layer in range(n_inputs)]} for i in range(n_neurons)]\n",
    "\tnetwork.append(hidden_layer1)\n",
    "\thidden_layer2 = [{'weights' :[random() for layer in range(n_neurons)]} for i in range(n_neurons)]\n",
    "\tnetwork.append(hidden_layer2)\n",
    "\toutput_layer = [{'weights' :[random() for layer in range(n_neurons)]} for i in range(n_outputs)]\n",
    "\tnetwork.append(output_layer)\n",
    "\treturn network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the input and weights initialization\n",
    "Print the layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The product summation and sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def weights_input_product(weights, inputs):\n",
    "\tsummation = 0\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tsummation += weights[i] * inputs[i]\n",
    "\treturn summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    if(z > 0):\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Send the list of outputs for each layer\n",
    "def forward_propagate(network, inputData):\n",
    "    outputs = []\n",
    "    inputRecord = inputData\n",
    "    relu_op = np.vectorize(lambda data: relu(data))\n",
    "    for layer in network: # Iterate over the layers\n",
    "        layer_output = []\n",
    "        i = 0\n",
    "        for neuron in layer: # Iterate for all neurons\n",
    "            summation = weights_input_product(neuron['weights'],inputRecord)\n",
    "            if i < len(network):\n",
    "                activation = relu_op(summation)\n",
    "            else:\n",
    "                activation = softmax(summation)\n",
    "            neuron['output'] = activation\n",
    "            layer_output.append(activation)\n",
    "        outputs.append(layer_output)\n",
    "        inputRecord = layer_output\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    sum = np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    return np.divide(np.exp(z),sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(z):\n",
    "    if(z > 0):\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "def transfer_softmax_derivative1(signal):\n",
    "    return signal*(1-signal) + (1 - signal)*signal\n",
    "\n",
    "\n",
    "def transfer_softmax_derivative(signal):\n",
    "    return np.multiply( signal, 1 - signal ) + sum(\n",
    "            # handle the off-diagonal values\n",
    "            - signal * np.roll( signal, i, axis = 1 )\n",
    "            for i in xrange(1, signal.shape[1] )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tif j != len(network)-1:\n",
    "\t\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])#Sigmoid derivative for all other layers\n",
    "\t\t\telse:\n",
    "\t\t\t\tneuron['delta'] = errors[j] * transfer_softmax_derivative(neuron['output'])#softmax derivative for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\tif i != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train via SGD\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs,n_iterations):\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tn_examples = len(train)        \n",
    "\t\trandom_samples = train[np.random.choice(train.shape[0], n_iterations, replace=False), :];\n",
    "\t\tfor row in random_samples:\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\t#print(\"Expected shape\",expected)\n",
    "\t\t\texpected[int(row[-1])] = 1\n",
    "\t\t\t#expected[1] = 1\n",
    "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\t\tprint('Epoch=%d, Loss=%.3f' % (epoch, sum_error))\n",
    "    \n",
    "\tprint(\"\\n\\nFinal Weights\")\n",
    "\tfor layer in network:\n",
    "\t\tlayerWeights = []\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tlayerWeights.append(neuron['weights'])\n",
    "\t\tprint layerWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    sum = np.sum(np.exp(z))\n",
    "    return np.divide(np.exp(z),sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "p =[ 0.0871086  , 0.91817548]\n",
    "\n",
    "def predict(network, row):\n",
    "\tp=outputs = forward_propagate(network, row)\n",
    "\t#print(outputs[0],outputs[1])\n",
    "\t#print(np.asarray(outputs).T)\n",
    "\treturn outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0, Loss=51.035\n",
      "Epoch=1, Loss=49.535\n",
      "Epoch=2, Loss=46.118\n",
      "Epoch=3, Loss=43.116\n",
      "Epoch=4, Loss=20.726\n",
      "Epoch=5, Loss=7.149\n",
      "Epoch=6, Loss=3.621\n",
      "Epoch=7, Loss=3.027\n",
      "Epoch=8, Loss=3.661\n",
      "Epoch=9, Loss=3.900\n",
      "Epoch=10, Loss=3.681\n",
      "Epoch=11, Loss=7.758\n",
      "Epoch=12, Loss=5.424\n",
      "Epoch=13, Loss=1.143\n",
      "Epoch=14, Loss=2.025\n",
      "Epoch=15, Loss=4.786\n",
      "Epoch=16, Loss=2.426\n",
      "Epoch=17, Loss=0.495\n",
      "Epoch=18, Loss=2.582\n",
      "Epoch=19, Loss=1.445\n",
      "Epoch=20, Loss=4.000\n",
      "Epoch=21, Loss=0.982\n",
      "Epoch=22, Loss=5.253\n",
      "Epoch=23, Loss=5.703\n",
      "Epoch=24, Loss=2.592\n",
      "Epoch=25, Loss=3.885\n",
      "Epoch=26, Loss=4.435\n",
      "Epoch=27, Loss=0.690\n",
      "Epoch=28, Loss=2.510\n",
      "Epoch=29, Loss=0.247\n",
      "Epoch=30, Loss=2.662\n",
      "Epoch=31, Loss=3.023\n",
      "Epoch=32, Loss=3.933\n",
      "Epoch=33, Loss=5.272\n",
      "Epoch=34, Loss=5.237\n",
      "Epoch=35, Loss=1.983\n",
      "Epoch=36, Loss=0.692\n",
      "Epoch=37, Loss=0.406\n",
      "Epoch=38, Loss=1.065\n",
      "Epoch=39, Loss=0.684\n",
      "Epoch=40, Loss=2.374\n",
      "Epoch=41, Loss=5.188\n",
      "Epoch=42, Loss=2.491\n",
      "Epoch=43, Loss=3.998\n",
      "Epoch=44, Loss=1.046\n",
      "Epoch=45, Loss=2.353\n",
      "Epoch=46, Loss=3.977\n",
      "Epoch=47, Loss=2.044\n",
      "Epoch=48, Loss=6.679\n",
      "Epoch=49, Loss=2.758\n",
      "\n",
      "\n",
      "Final Weights\n",
      "[[-2.9268607380144198, 306.4769722199423], [3.0839513199559101, -230.07492301104932], [-3.4380705562169749, 566.94763929435817]]\n",
      "[[2.8786772272158925, -2.3475941066735526, 0.83578215575001946], [-3.213893533568025, 3.3278189791031072, -3.9577072239961684], [8.241264414628457, -4.2945478226644944, 9.9587434119433365]]\n",
      "[[-3.8389788892097316, 4.4428003801111018, -17.418767803174333], [3.8493039175523864, -4.4551634506894775, 14.222084140900554]]\n",
      "\n",
      "Training Precision=0.98\n",
      "Training Recall=0.98\n",
      "Training F1 Score=0.98\n",
      "\n",
      "---------------------------- Testing the predictions -------------------------\n",
      "\n",
      "Test Precision=0.98\n",
      "Test Recall=0.98\n",
      "Test F1 Score=0.98\n"
     ]
    }
   ],
   "source": [
    "# Run the code now\n",
    "\n",
    "#Do the training first.\n",
    "seed(1)\n",
    "inputFilenameWithPath = 'train_data.txt'\n",
    "prediction_op = np.vectorize(lambda data: predict(network, data))\n",
    "inputData = np.loadtxt(inputFilenameWithPath, delimiter=\",\")\n",
    "n_inputs = len(inputData[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in inputData]))\n",
    "n_neurons = 3\n",
    "network = initialize_network(n_inputs, n_neurons, n_outputs)\n",
    "sgd_learning_rate = 0.6\n",
    "numberOfEpochs  = 50\n",
    "numberOfExamplesPerEpoch = 100\n",
    "train_network(network, inputData, sgd_learning_rate, numberOfEpochs, n_outputs,numberOfExamplesPerEpoch)\n",
    "predictions = []\n",
    "truth = inputData[:,2]\n",
    "for row in inputData:\n",
    "\tprediction = predict(network, row)\n",
    "\tpredictions.append(prediction)\n",
    "f1 = skl.metrics.f1_score(truth, predictions, average='micro')  \n",
    "precision = skl.metrics.precision_score(truth, predictions, average='micro')\n",
    "recall = skl.metrics.recall_score(truth, predictions, average='micro')\n",
    "print('\\nTraining Precision=%.2f' % (precision))\n",
    "print('Training Recall=%.2f' % (recall))\n",
    "print('Training F1 Score=%.2f' % (f1))\n",
    "    \n",
    "print('\\n---------------------------- Testing the predictions -------------------------')    \n",
    "# Test making predictions with the network\n",
    "inputFilenameWithPath = 'test_data.txt'\n",
    "dataset = np.loadtxt(inputFilenameWithPath, delimiter=\",\")\n",
    "\n",
    "#predictions = prediction_op(dataset[:,:2])\n",
    "truth = dataset[:,2]\n",
    "predictions = []\n",
    "for row in dataset:\n",
    "\tprediction = predict(network, row)\n",
    "\tpredictions.append(prediction)\n",
    "\t#print('Expected=%d, Got=%d' % (row[-1], prediction))\n",
    "f1 = skl.metrics.f1_score(truth, predictions, average='micro')  \n",
    "precision = skl.metrics.precision_score(truth, predictions, average='micro')\n",
    "recall = skl.metrics.recall_score(truth, predictions, average='micro')\n",
    "print('\\nTest Precision=%.2f' % (precision))\n",
    "print('Test Recall=%.2f' % (recall))\n",
    "print('Test F1 Score=%.2f' % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The scores for the Assignment 1 were also precisely the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
