{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.68491' '0.32385' '-0.11592' ..., '0.17874' '-0.1693' '0.062375']\n",
      " ['0.96193' '0.012516' '0.21733' ..., '0.14032' '-0.38468' '-0.38712']\n",
      " ['0.6008' '0.18044' '0.078339' ..., '-0.016404' '-0.65372' '-0.38255']\n",
      " ..., \n",
      " ['0.88387' '-0.14199' '0.13566' ..., '0.52711' '-0.20148' '0.0095952']\n",
      " ['-0.0010919' '0.33324' '0.35743' ..., '-0.45697' '-0.048969' '1.1316']\n",
      " ['-0.55114' '-0.16296' '-0.95494' ..., '-1.0346' '-0.25143' '1.4836']]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = 'MNIST'\n",
    "sentiment_data = 'sentiment-data'\n",
    "\n",
    "\n",
    "def getWordVectorDict():\n",
    "    reader = csv.reader(open(sentiment_data +'/word-vectors-refine.txt'))\n",
    "\n",
    "    word_vector_dict = {}\n",
    "    for row in reader:\n",
    "        key = row[0]\n",
    "        if key in word_vector_dict:\n",
    "            # implement your duplicate row handling here\n",
    "            pass\n",
    "        word_vector_dict[key] = np.array(row[1:])\n",
    "    return word_vector_dict\n",
    "\n",
    "def getPaddedSentenceMatrix(sentenceMatrix):\n",
    "    wordCount = 100\n",
    "    return np.vstack((sentenceMatrix, np.zeros((wordCount - np.shape(sentenceMatrix)[0],np.shape(sentenceMatrix)[1]), dtype=np.float32)))\n",
    "\n",
    "def getVectorForSentence(sentence, word_vec_dict):\n",
    "    sentence_matrix = []\n",
    "    for word in sentence.split(' '):\n",
    "        word_vec = word_vec_dict[word]\n",
    "        if(len(sentence_matrix) == 0):\n",
    "            sentence_matrix = word_vec\n",
    "        else:\n",
    "            sentence_matrix = np.vstack((sentence_matrix,word_vec))\n",
    "    return getPaddedSentenceMatrix(sentence_matrix)\n",
    "\n",
    "def getData(fileName):\n",
    "    reader = csv.reader(open(sentiment_data +'/' + fileName))\n",
    "    trainingData = []\n",
    "    for row in reader:\n",
    "        data = {}\n",
    "        data['label'] =  1 if row[0] == 'postive' else 0\n",
    "        data['sentence'] = row[1:]\n",
    "        trainingData.append(data)\n",
    "    return trainingData\n",
    "\n",
    "word_vec_dict = getWordVectorDict()\n",
    "\n",
    "\n",
    "def transform(row):\n",
    "    return row['label'], getVectorForSentence(row['sentence'][0], word_vec_dict)\n",
    "\n",
    "\n",
    "word_vector_size = 50;\n",
    "time_steps = 100;\n",
    "num_classes = 2\n",
    "batch_size = 1000;\n",
    "n_iterations = 10;\n",
    "hidden_layer_size = 64\n",
    "\n",
    "training_data = getData('train.csv')\n",
    "training_rows  = map(lambda row: transform(row), training_data)\n",
    "training_data = map(lambda row: row[1], training_rows)\n",
    "training_labels = map(lambda row: row[0], training_rows)\n",
    "#test_data = map(lambda row: transform(row), getData('test.csv'))\n",
    "test_data = getData('test.csv')\n",
    "test_rows  = map(lambda row: transform(row), test_data)\n",
    "test_data = map(lambda row: row[1], test_rows)\n",
    "test_labels = map(lambda row: row[0], test_rows)\n",
    "print training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Setting up the input and labels placeholders\n",
    "_inputs = tf.placeholder(tf.float32, shape=[None, time_steps,\n",
    "                                            word_vector_size])\n",
    "y = tf.placeholder(tf.int32, shape=[None, num_classes])\n",
    "y_one_hot = tf.one_hot( y , num_classes )\n",
    "\n",
    "# TensorFlow built-in functions\n",
    "# Creating the RNN cell and creating the outputs\n",
    "with tf.variable_scope(\"gru\"):\n",
    "    gru_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "    outputs, states = tf.nn.dynamic_rnn(gru_cell,_inputs, dtype=tf.float32)\n",
    "    final_output = tf.layers.dense(states, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits = final_output,\n",
    "                                                  labels = y)                         \n",
    "cross_entropy = tf.reduce_mean(softmax)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9)\n",
    "gvs = optimizer.compute_gradients(cross_entropy)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_step = optimizer.apply_gradients(capped_gvs)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),\n",
    "                              tf.argmax(final_output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction,\n",
    "                                   tf.float32)))*100\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "  num_labels = labels_dense.shape[0]\n",
    "  index_offset = np.arange(num_labels) * num_classes\n",
    "  labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "  return labels_one_hot\n",
    "\n",
    "label_batch = np.array(training_labels[100 : 200])\n",
    "l = np.array(dense_to_one_hot(label_batch,2)).reshape(len(label_batch), num_classes)\n",
    "\n",
    "print l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iter 0, Minibatch Loss= 0.697023, Training Accuracy= 50.00000\n",
      "(100, 64)\n",
      "(100, 100, 64)\n",
      "[ 0.5162347  -0.11819154 -0.5463233   0.5598706  -0.19427732 -0.25532776\n",
      "  0.11919738  0.66415358  0.24820271 -0.6127857   0.409504   -0.15468313\n",
      "  0.73689514 -0.49753702  0.00544862 -0.22898878  0.40075496  0.08938645\n",
      "  0.06321375 -0.09962279  0.18321204  0.33886611 -0.35042232 -0.86028928\n",
      "  0.55071449 -0.22403556 -0.11768804 -0.5925293   0.57846802  0.44640893\n",
      "  0.01750622 -0.02580878  0.12711397 -0.47312716  0.32164839  0.40020624\n",
      " -0.65026784  0.05934783 -0.50766468  0.29480997 -0.20243013 -0.38786352\n",
      "  0.6475563  -0.59787196 -0.59995413 -0.66767967 -0.39042392 -0.26720676\n",
      " -0.46581605  0.59464693  0.19762833 -0.53131968 -0.55406857 -0.41526851\n",
      " -0.35170147 -0.70137882  0.05803543  0.05674836  0.62532026  0.24105331\n",
      "  0.27033341  0.27540094  0.50771028  0.39567053]\n",
      "[ 0.5162347  -0.11819154 -0.5463233   0.5598706  -0.19427732 -0.25532776\n",
      "  0.11919738  0.66415358  0.24820271 -0.6127857   0.409504   -0.15468313\n",
      "  0.73689514 -0.49753702  0.00544862 -0.22898878  0.40075496  0.08938645\n",
      "  0.06321375 -0.09962279  0.18321204  0.33886611 -0.35042232 -0.86028928\n",
      "  0.55071449 -0.22403556 -0.11768804 -0.5925293   0.57846802  0.44640893\n",
      "  0.01750622 -0.02580878  0.12711397 -0.47312716  0.32164839  0.40020624\n",
      " -0.65026784  0.05934783 -0.50766468  0.29480997 -0.20243013 -0.38786352\n",
      "  0.6475563  -0.59787196 -0.59995413 -0.66767967 -0.39042392 -0.26720676\n",
      " -0.46581605  0.59464693  0.19762833 -0.53131968 -0.55406857 -0.41526851\n",
      " -0.35170147 -0.70137882  0.05803543  0.05674836  0.62532026  0.24105331\n",
      "  0.27033341  0.27540094  0.50771028  0.39567053]\n",
      "(64,)\n",
      "Epoch: 1\n",
      "Iter 1, Minibatch Loss= 0.570703, Training Accuracy= 73.00000\n",
      "(100, 64)\n",
      "(100, 100, 64)\n",
      "[ 0.60422218 -0.13462499 -0.58502364  0.57535714 -0.28630811  0.07341144\n",
      "  0.18884625  0.52293074  0.36620277 -0.40379259  0.00173556 -0.16208902\n",
      "  0.80841196 -0.06174165  0.00271562 -0.43135041  0.54862124  0.23169975\n",
      "  0.23533639  0.24272315  0.18154559  0.43380386 -0.37999266 -0.81249249\n",
      "  0.63612336  0.33171904 -0.37814373 -0.6586594   0.67310065  0.15212962\n",
      " -0.05698064 -0.16690397 -0.09359328 -0.08094245  0.44386557  0.44431937\n",
      " -0.48057172  0.28081116 -0.48987895  0.51057982  0.06970655 -0.28982809\n",
      "  0.43562067 -0.68922031 -0.53356719 -0.53205276 -0.20754816  0.12710175\n",
      " -0.4344255   0.51195866 -0.1600244  -0.21578999 -0.49863884 -0.21270944\n",
      " -0.19345769 -0.63865137 -0.02229531  0.31503698  0.6734302   0.22234829\n",
      "  0.09360346  0.3362861   0.19933234  0.41874355]\n",
      "[ 0.60422218 -0.13462499 -0.58502364  0.57535714 -0.28630811  0.07341144\n",
      "  0.18884625  0.52293074  0.36620277 -0.40379259  0.00173556 -0.16208902\n",
      "  0.80841196 -0.06174165  0.00271562 -0.43135041  0.54862124  0.23169975\n",
      "  0.23533639  0.24272315  0.18154559  0.43380386 -0.37999266 -0.81249249\n",
      "  0.63612336  0.33171904 -0.37814373 -0.6586594   0.67310065  0.15212962\n",
      " -0.05698064 -0.16690397 -0.09359328 -0.08094245  0.44386557  0.44431937\n",
      " -0.48057172  0.28081116 -0.48987895  0.51057982  0.06970655 -0.28982809\n",
      "  0.43562067 -0.68922031 -0.53356719 -0.53205276 -0.20754816  0.12710175\n",
      " -0.4344255   0.51195866 -0.1600244  -0.21578999 -0.49863884 -0.21270944\n",
      " -0.19345769 -0.63865137 -0.02229531  0.31503698  0.6734302   0.22234829\n",
      "  0.09360346  0.3362861   0.19933234  0.41874355]\n",
      "(64,)\n",
      "Epoch: 2\n",
      "Iter 2, Minibatch Loss= 0.517802, Training Accuracy= 78.00000\n",
      "(100, 64)\n",
      "(100, 100, 64)\n",
      "[ 0.58588713 -0.10268816 -0.63845557  0.46082199 -0.25316823  0.09664419\n",
      "  0.20248102  0.50397903  0.35368755 -0.25532588  0.05400345 -0.17756151\n",
      "  0.78994232 -0.031997    0.01254444 -0.39299086  0.55155456  0.22817348\n",
      "  0.22967196  0.28993887  0.18903328  0.37449625 -0.45375246 -0.76029778\n",
      "  0.59766209  0.31745279 -0.38864005 -0.62747037  0.59188259  0.07078619\n",
      " -0.05278334 -0.16321975 -0.15529153  0.05590245  0.45022434  0.46140867\n",
      " -0.2753095   0.28347301 -0.39044464  0.51882899  0.02657362 -0.21955562\n",
      "  0.31040549 -0.63703394 -0.42307264 -0.48078215 -0.05472317  0.19045\n",
      " -0.41188556  0.458987   -0.19547988 -0.02741096 -0.46319646 -0.03611055\n",
      " -0.11007346 -0.574166    0.03930084  0.36263356  0.6816892   0.1496044\n",
      "  0.13048634  0.31884772  0.12127629  0.41393739]\n",
      "[ 0.58588713 -0.10268816 -0.63845557  0.46082199 -0.25316823  0.09664419\n",
      "  0.20248102  0.50397903  0.35368755 -0.25532588  0.05400345 -0.17756151\n",
      "  0.78994232 -0.031997    0.01254444 -0.39299086  0.55155456  0.22817348\n",
      "  0.22967196  0.28993887  0.18903328  0.37449625 -0.45375246 -0.76029778\n",
      "  0.59766209  0.31745279 -0.38864005 -0.62747037  0.59188259  0.07078619\n",
      " -0.05278334 -0.16321975 -0.15529153  0.05590245  0.45022434  0.46140867\n",
      " -0.2753095   0.28347301 -0.39044464  0.51882899  0.02657362 -0.21955562\n",
      "  0.31040549 -0.63703394 -0.42307264 -0.48078215 -0.05472317  0.19045\n",
      " -0.41188556  0.458987   -0.19547988 -0.02741096 -0.46319646 -0.03611055\n",
      " -0.11007346 -0.574166    0.03930084  0.36263356  0.6816892   0.1496044\n",
      "  0.13048634  0.31884772  0.12127629  0.41393739]\n",
      "(64,)\n",
      "Epoch: 3\n",
      "Iter 3, Minibatch Loss= 0.474525, Training Accuracy= 81.00000\n",
      "(100, 64)\n",
      "(100, 100, 64)\n",
      "[ 0.60238969 -0.10722203 -0.70983809  0.47789878 -0.29239008  0.19614397\n",
      "  0.14108288  0.48581052  0.39833549 -0.13331757 -0.00287116 -0.17350218\n",
      "  0.79551882 -0.06154991  0.06123766 -0.43503183  0.61739177  0.22013539\n",
      "  0.21148947  0.34706527  0.22908133  0.38542393 -0.50496161 -0.72364533\n",
      "  0.61407542  0.44578445 -0.42680568 -0.66873944  0.60008574 -0.01510631\n",
      " -0.04759714 -0.21718925 -0.25527823  0.20678784  0.46491849  0.46835026\n",
      " -0.13075969  0.38387251 -0.39309415  0.57631302  0.05392811 -0.14255369\n",
      "  0.22154683 -0.65854895 -0.34863108 -0.41564646 -0.04422683  0.2802583\n",
      " -0.39100271  0.42006904 -0.29756689  0.02318157 -0.42965609  0.03040952\n",
      " -0.09301944 -0.57573372  0.05104516  0.453747    0.71809667  0.14681941\n",
      "  0.08601286  0.31540817  0.04494863  0.44310087]\n",
      "[ 0.60238969 -0.10722203 -0.70983809  0.47789878 -0.29239008  0.19614397\n",
      "  0.14108288  0.48581052  0.39833549 -0.13331757 -0.00287116 -0.17350218\n",
      "  0.79551882 -0.06154991  0.06123766 -0.43503183  0.61739177  0.22013539\n",
      "  0.21148947  0.34706527  0.22908133  0.38542393 -0.50496161 -0.72364533\n",
      "  0.61407542  0.44578445 -0.42680568 -0.66873944  0.60008574 -0.01510631\n",
      " -0.04759714 -0.21718925 -0.25527823  0.20678784  0.46491849  0.46835026\n",
      " -0.13075969  0.38387251 -0.39309415  0.57631302  0.05392811 -0.14255369\n",
      "  0.22154683 -0.65854895 -0.34863108 -0.41564646 -0.04422683  0.2802583\n",
      " -0.39100271  0.42006904 -0.29756689  0.02318157 -0.42965609  0.03040952\n",
      " -0.09301944 -0.57573372  0.05104516  0.453747    0.71809667  0.14681941\n",
      "  0.08601286  0.31540817  0.04494863  0.44310087]\n",
      "(64,)\n",
      "Epoch: 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5098b8cea81a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_to_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstartIndex\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mendIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             sess.run(train_step, feed_dict={_inputs: batch_x,\n\u001b[0;32m---> 19\u001b[0;31m                                             y: batch_y})\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100;\n",
    "n_iterations = 20;\n",
    "\n",
    "#Initialize session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(n_iterations):\n",
    "        print \"Epoch:\", epoch\n",
    "        for j in range(len(training_data)/batch_size):\n",
    "            #print \"j:\", j\n",
    "            if(j == 100):\n",
    "                break\n",
    "            startIndex = j*batch_size\n",
    "            endIndex = startIndex + batch_size\n",
    "            batch_x = np.array(training_data[startIndex : endIndex]).reshape((-1,time_steps, word_vector_size))\n",
    "            batch_y = dense_to_one_hot(np.array(training_labels[startIndex : endIndex]),num_classes)\n",
    "            sess.run(train_step, feed_dict={_inputs: batch_x,\n",
    "                                            y: batch_y})\n",
    "        if epoch % 1 == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={_inputs: batch_x, y: batch_y})\n",
    "            loss = sess.run(cross_entropy, feed_dict={_inputs: batch_x, y: batch_y})\n",
    "            print (\"Iter \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                    \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                    \"{:.5f}\".format(acc))\n",
    "            \n",
    "            _states = np.array(sess.run(states, feed_dict={_inputs: batch_x, y: batch_y}))\n",
    "            _outputs = np.array(sess.run(outputs, feed_dict={_inputs: batch_x, y: batch_y}))\n",
    "      \n",
    "            final_op = _outputs[-1][-1]\n",
    "            #final_op = final_op[-1]\n",
    "            print (_states.shape)\n",
    "            print (_outputs.shape)\n",
    "            print (_states[-1])\n",
    "            print (final_op)\n",
    "            print (final_op.shape)\n",
    "\n",
    "\n",
    "    print (\"Testing Accuracy:\",\n",
    "        sess.run(accuracy, feed_dict={_inputs: test_data, y: dense_to_one_hot(np.array(test_labels), num_classes)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracies for the RNN, LSTM and GRU are 70.7%, 78.08% and 77.26% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "        'linear_layer': tf.Variable(tf.truncated_normal([hidden_layer_size,\n",
    "                                                         num_classes],\n",
    "                                                         mean=0,stddev=.01))\n",
    "}\n",
    "\n",
    "\n",
    "# Extract the last relevant output and use in a linear layer\n",
    "final_output = tf.matmul(states,\n",
    "                         weights[\"linear_layer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
