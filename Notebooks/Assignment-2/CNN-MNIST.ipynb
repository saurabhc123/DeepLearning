{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'MNIST'\n",
    "STEPS = 5000\n",
    "MINIBATCH_SIZE = 100\n",
    "\n",
    "imgDim = 28\n",
    "imgChannels = 1\n",
    "nClasses = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, name1):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME',name = name1)\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def conv_layer(input, shape, name1):\n",
    "    W = weight_variable(shape,)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W, name1) + b)\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def display_images(images, size):\n",
    "    n = len(images)\n",
    "    plt.figure()\n",
    "    plt.gca().set_axis_off()\n",
    "    im = np.hstack([images[i] for i in range(size)])\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "def display_custom1(custom_item):\n",
    "    n_items = custom_item.shape[3]\n",
    "    for i in range(n_items):\n",
    "        plt.imshow(cv1[0,:,:,i],cmap = \"gray\")\n",
    "        plt.show()\n",
    "\n",
    "def display_custom(custom_item, i):\n",
    "    plotNNFilter(custom_item, i)\n",
    "        \n",
    "        \n",
    "def plotNNFilter(units, image_index):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(image_index, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[image_index,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        \n",
    "def plotNNFeatureMap(units, image_index):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(image_index, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Feature Map' + str(i))\n",
    "        plt.imshow(units[image_index,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "conv1 = conv_layer(x_image, shape=[5, 5, 1, 32],name1 = 'conv1')\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "conv2 = conv_layer(conv1_pool, shape=[5, 5, 32, 64],name1 = 'conv2')\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 7 * 7 * 64])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "y_conv = full_layer(full1_drop, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.20000000298\n",
      "test accuracy: 0.115100003779\n",
      "[u'Variable:0', u'Variable_1:0', u'Variable_2:0', u'Variable_3:0', u'Variable_4:0', u'Variable_5:0', u'Variable_6:0', u'Variable_7:0', u'beta1_power:0', u'beta2_power:0', u'Variable/Adam:0', u'Variable/Adam_1:0', u'Variable_1/Adam:0', u'Variable_1/Adam_1:0', u'Variable_2/Adam:0', u'Variable_2/Adam_1:0', u'Variable_3/Adam:0', u'Variable_3/Adam_1:0', u'Variable_4/Adam:0', u'Variable_4/Adam_1:0', u'Variable_5/Adam:0', u'Variable_5/Adam_1:0', u'Variable_6/Adam:0', u'Variable_6/Adam_1:0', u'Variable_7/Adam:0', u'Variable_7/Adam_1:0', u'beta1_power_1:0', u'beta2_power_1:0', u'Variable/Adam_2:0', u'Variable/Adam_3:0', u'Variable_1/Adam_2:0', u'Variable_1/Adam_3:0', u'Variable_2/Adam_2:0', u'Variable_2/Adam_3:0', u'Variable_3/Adam_2:0', u'Variable_3/Adam_3:0', u'Variable_4/Adam_2:0', u'Variable_4/Adam_3:0', u'Variable_5/Adam_2:0', u'Variable_5/Adam_3:0', u'Variable_6/Adam_2:0', u'Variable_6/Adam_3:0', u'Variable_7/Adam_2:0', u'Variable_7/Adam_3:0', u'beta1_power_2:0', u'beta2_power_2:0', u'Variable/Adam_4:0', u'Variable/Adam_5:0', u'Variable_1/Adam_4:0', u'Variable_1/Adam_5:0', u'Variable_2/Adam_4:0', u'Variable_2/Adam_5:0', u'Variable_3/Adam_4:0', u'Variable_3/Adam_5:0', u'Variable_4/Adam_4:0', u'Variable_4/Adam_5:0', u'Variable_5/Adam_4:0', u'Variable_5/Adam_5:0', u'Variable_6/Adam_4:0', u'Variable_6/Adam_5:0', u'Variable_7/Adam_4:0', u'Variable_7/Adam_5:0', u'beta1_power_3:0', u'beta2_power_3:0', u'Variable/Adam_6:0', u'Variable/Adam_7:0', u'Variable_1/Adam_6:0', u'Variable_1/Adam_7:0', u'Variable_2/Adam_6:0', u'Variable_2/Adam_7:0', u'Variable_3/Adam_6:0', u'Variable_3/Adam_7:0', u'Variable_4/Adam_6:0', u'Variable_4/Adam_7:0', u'Variable_5/Adam_6:0', u'Variable_5/Adam_7:0', u'Variable_6/Adam_6:0', u'Variable_6/Adam_7:0', u'Variable_7/Adam_6:0', u'Variable_7/Adam_7:0', u'beta1_power_4:0', u'beta2_power_4:0', u'Variable/Adam_8:0', u'Variable/Adam_9:0', u'Variable_1/Adam_8:0', u'Variable_1/Adam_9:0', u'Variable_2/Adam_8:0', u'Variable_2/Adam_9:0', u'Variable_3/Adam_8:0', u'Variable_3/Adam_9:0', u'Variable_4/Adam_8:0', u'Variable_4/Adam_9:0', u'Variable_5/Adam_8:0', u'Variable_5/Adam_9:0', u'Variable_6/Adam_8:0', u'Variable_6/Adam_9:0', u'Variable_7/Adam_8:0', u'Variable_7/Adam_9:0']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of a new variable (conv1) must be fully defined, but instead was <unknown>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-913a0096e5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdisplay_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/saur6410/.virtualenvs/blacksburg/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n\u001b[0;32m--> 685\u001b[0;31m                        \"but instead was %s.\" % (name, shape))\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;31m# Create the tensor to initialize the variable with default value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of a new variable (conv1) must be fully defined, but instead was <unknown>."
     ]
    }
   ],
   "source": [
    "STEPS = 2  #Ideal value 2000\n",
    "MINIBATCH_SIZE = 5 #Ideal value 400\n",
    "\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv,labels= y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(STEPS):\n",
    "        batch = mnist.train.next_batch(MINIBATCH_SIZE)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print \"step {}, training accuracy {}\".format(i, train_accuracy)\n",
    "            sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "            X = mnist.test.images.reshape(10, 1000, 784)\n",
    "            Y = mnist.test.labels.reshape(10, 1000, 10)\n",
    "            test_accuracy = np.mean([sess.run(accuracy,feed_dict = {x: X[i], y_: Y[i],keep_prob: 1.0})\n",
    "                                      for i in range(10)])\n",
    "    print \"test accuracy: {}\".format(test_accuracy)\n",
    "    render_batch = mnist.test.next_batch(9)\n",
    "    images = render_batch[0].reshape(9,28,28)\n",
    "    cv1 = sess.run(conv1,feed_dict = {x: render_batch[0]})\n",
    "    for i in range(np.array(cv1).shape[0]):\n",
    "        display_custom(np.array(cv1),i)\n",
    "    print [v.name for v in tf.global_variables()]\n",
    "    #The below is not working\n",
    "    weights = tf.get_variable('conv1')\n",
    "    print weights\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        weights = tf.get_variable('conv1')\n",
    "        print weights\n",
    "    #make the above segment work.\n",
    "    labs = sess.run(tf.argmax(y_conv, 1),feed_dict = {x: render_batch[0], y_: render_batch[1],keep_prob: 1.0})\n",
    "    print \"Predicted Labels:\", labs\n",
    "    display_images(images,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_custom(np.array(cv1),0)\n",
    "print cv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}